{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM4r93bCQY6lSnZ5PGvFXSG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sohataher/NLP-Course/blob/main/NLP_Day2_NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy init fill-config base_config.cfg config.cfg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTAG5GVNukQv",
        "outputId": "17650641-84b5-4006-a1af-212ef8dfff6d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "\n",
        "# Load spaCy model\n",
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"ner.csv\")\n",
        "\n",
        "# Forward fill sentence IDs if needed\n",
        "df = df.ffill()\n",
        "\n",
        "# Convert string representations of lists into actual lists\n",
        "df['POS'] = df['POS'].apply(ast.literal_eval)\n",
        "df['Tag'] = df['Tag'].apply(ast.literal_eval)\n",
        "\n",
        "# Check and match lengths\n",
        "def is_valid_row(row):\n",
        "    return len(row['Sentence'].split()) == len(row['POS']) == len(row['Tag'])\n",
        "\n",
        "df = df[df.apply(is_valid_row, axis=1)]\n",
        "\n",
        "# Split into train and dev\n",
        "train_df = df.sample(frac=0.8, random_state=42)\n",
        "dev_df = df.drop(train_df.index)\n",
        "\n",
        "# Convert to spaCy DocBin\n",
        "def convert_to_docbin(dataframe, filename):\n",
        "    db = DocBin()\n",
        "    for _, row in dataframe.iterrows():\n",
        "        doc = nlp.make_doc(row['Sentence'])\n",
        "        ents = []\n",
        "        words = row['Sentence'].split()\n",
        "        tags = row['Tag']\n",
        "        offset = 0\n",
        "        for word, tag in zip(words, tags):\n",
        "            start = row['Sentence'].find(word, offset)\n",
        "            end = start + len(word)\n",
        "            if tag != \"O\":\n",
        "                label = tag.split(\"-\")[-1]\n",
        "                span = doc.char_span(start, end, label=label)\n",
        "                if span:\n",
        "                    ents.append(span)\n",
        "            offset = end\n",
        "        doc.ents = ents\n",
        "        db.add(doc)\n",
        "\n",
        "    # Save the DocBin object to disk\n",
        "    db.to_disk(filename)\n",
        "\n",
        "    # Print out a sample sentence from the DocBin to check the conversion\n",
        "    print(f\"\\nConverted {filename}: Sample data from the DocBin:\")\n",
        "    doc_bin = DocBin().from_disk(filename)\n",
        "    docs = list(doc_bin.get_docs(nlp.vocab))  # Convert generator to list\n",
        "    if docs:\n",
        "        sample_doc = docs[0]\n",
        "        print(\"Text:\", sample_doc.text)\n",
        "        for ent in sample_doc.ents:\n",
        "            print(f\"Entity: {ent.text}, Label: {ent.label_}\")\n",
        "    else:\n",
        "        print(\"No documents found.\")\n",
        "\n",
        "# Convert to DocBin and check sample data\n",
        "convert_to_docbin(train_df, \"train.spacy\")\n",
        "convert_to_docbin(dev_df, \"dev.spacy\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_liE6bJ3ivo8",
        "outputId": "9f2445ce-0d3e-49a7-feef-411f1bd94697"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Converted train.spacy: Sample data from the DocBin:\n",
            "Text: On the Republican side , Senator John McCain seems on the verge of clinching his party 's nomination .\n",
            "Entity: Senator, Label: per\n",
            "Entity: John, Label: per\n",
            "Entity: McCain, Label: per\n",
            "\n",
            "Converted dev.spacy: Sample data from the DocBin:\n",
            "Text: They marched from the Houses of Parliament to a rally in Hyde Park .\n",
            "Entity: Hyde, Label: geo\n",
            "Entity: Park, Label: geo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZE9VYceA1Ii",
        "outputId": "e2cbe1b7-7a61-4108-bb28-82831cb160ac"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-lg==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl (400.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.7/400.7 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy train config.cfg --output ./output --paths.train ./train.spacy --paths.dev ./dev.spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahO6nQoQ8Aw8",
        "outputId": "66793952-a807-4c43-f3f6-df47ed3157ad"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[38;5;4mℹ To switch to GPU 0, use the option: --gpu-id 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00     44.21    1.46    3.78    0.91    0.01\n",
            "  0     200         21.48   2622.10   75.24   76.93   73.63    0.75\n",
            "  0     400         60.67   1782.43   78.41   78.03   78.79    0.78\n",
            "  0     600         36.58   1941.12   81.70   82.50   80.91    0.82\n",
            "  0     800         45.69   2265.85   82.71   81.09   84.39    0.83\n",
            "  0    1000         54.29   2509.12   83.92   84.46   83.38    0.84\n",
            "  0    1200         61.49   2838.34   84.21   84.84   83.59    0.84\n",
            "  0    1400         81.75   3524.73   84.89   85.69   84.11    0.85\n",
            "  0    1600        104.66   4176.09   83.43   84.15   82.73    0.83\n",
            "  0    1800        144.03   4895.85   85.99   87.76   84.29    0.86\n",
            "  0    2000        166.58   5960.03   86.45   86.59   86.31    0.86\n",
            "  0    2200        205.58   6938.44   86.90   87.28   86.52    0.87\n",
            "  1    2400        236.67   7392.97   87.04   87.51   86.58    0.87\n",
            "  1    2600        257.46   7230.42   87.35   88.55   86.18    0.87\n",
            "  1    2800        259.00   7297.49   86.87   86.22   87.53    0.87\n",
            "  1    3000        257.51   7050.67   87.52   88.72   86.35    0.88\n",
            "  2    3200        282.74   6902.55   87.47   88.18   86.78    0.87\n",
            "  2    3400        309.96   6176.00   86.98   88.80   85.24    0.87\n",
            "  2    3600        291.21   6299.31   87.76   88.37   87.17    0.88\n",
            "  2    3800        323.27   6377.95   87.31   86.30   88.35    0.87\n",
            "  2    4000        317.39   6370.09   87.72   87.82   87.63    0.88\n",
            "  3    4200        300.74   5513.22   87.47   88.64   86.34    0.87\n",
            "  3    4400        352.84   5709.39   87.61   88.71   86.54    0.88\n",
            "  3    4600        354.31   5790.96   87.47   88.17   86.77    0.87\n",
            "  3    4800        342.29   5742.10   87.73   87.98   87.49    0.88\n",
            "  4    5000        343.47   5285.84   87.89   88.49   87.29    0.88\n",
            "  4    5200        345.74   5033.30   87.71   88.32   87.11    0.88\n",
            "  4    5400        347.53   5198.85   87.60   88.10   87.10    0.88\n",
            "  4    5600        365.64   5375.46   87.57   87.89   87.25    0.88\n",
            "  5    5800        361.88   5174.07   87.51   88.76   86.30    0.88\n",
            "  5    6000        407.88   4372.94   87.21   87.80   86.62    0.87\n",
            "  5    6200        377.43   4864.39   87.76   88.23   87.30    0.88\n",
            "  5    6400        395.52   4843.82   87.25   87.74   86.76    0.87\n",
            "  5    6600        409.42   4929.37   87.69   88.22   87.17    0.88\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "output/model-last\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy evaluate ./output/model-best ./dev.spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyd8r9xi8UZs",
        "outputId": "1ef88f2b-48c0-45ee-bd04-87919db69cb3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[38;5;4mℹ To switch to GPU 0, use the option: --gpu-id 0\u001b[0m\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "TOK     100.00\n",
            "NER P   88.49 \n",
            "NER R   87.29 \n",
            "NER F   87.89 \n",
            "SPEED   3656  \n",
            "\n",
            "\u001b[1m\n",
            "=============================== NER (per type) ===============================\u001b[0m\n",
            "\n",
            "          P       R       F\n",
            "org   83.80   78.97   81.32\n",
            "geo   86.12   91.06   88.52\n",
            "gpe   95.39   95.09   95.24\n",
            "tim   93.47   89.41   91.40\n",
            "per   90.40   89.47   89.93\n",
            "art   14.63    4.41    6.78\n",
            "eve   58.00   23.39   33.33\n",
            "nat   89.47   35.42   50.75\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "model = spacy.load(\"./output/model-best\")"
      ],
      "metadata": {
        "id": "gNfeJc63DfBQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = model(\"Apple is looking to buy a startup in America\")\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zWQxjyAFslm",
        "outputId": "ec36dee7-cf63-4e18-e5c0-93c61d6f7b9b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple org\n",
            "America geo\n"
          ]
        }
      ]
    }
  ]
}